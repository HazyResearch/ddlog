
  deepdive.db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user: ${PGUSER}
    password: ${PGPASSWORD}
    dbname: ${DBNAME}
    host: ${PGHOST}
    port: ${PGPORT}
    incremental_mode: ORIGINAL
    }
    


      deepdive.schema.variables {
        has_spouse.label: Boolean
      }
    

          deepdive.extraction.extractors.init_sentences {
            sql: """ DROP TABLE IF EXISTS sentences CASCADE;
            CREATE TABLE
            sentences(document_id text,
         sentence text,
         words text[],
         lemma text[],
         pos_tags text[],
         dependencies text[],
         ner_tags text[],
         sentence_offset int,
         sentence_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_has_spouse_candidates {
            sql: """ DROP TABLE IF EXISTS has_spouse_candidates CASCADE;
            CREATE TABLE
            has_spouse_candidates(person1_id text,
                     person2_id text,
                     sentence_id text,
                     description text,
                     relation_id text,
                     is_true boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_has_spouse {
            sql: """ DROP TABLE IF EXISTS has_spouse CASCADE;
            CREATE TABLE
            has_spouse(relation_id text,
          id bigint,
          label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_articles {
            sql: """ DROP TABLE IF EXISTS articles CASCADE;
            CREATE TABLE
            articles(article_id text,
        text text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_has_spouse_features {
            sql: """ DROP TABLE IF EXISTS has_spouse_features CASCADE;
            CREATE TABLE
            has_spouse_features(relation_id text,
                   feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_people_mentions {
            sql: """ DROP TABLE IF EXISTS people_mentions CASCADE;
            CREATE TABLE
            people_mentions(sentence_id text,
               start_position int,
               length int,
               text text,
               mention_id text)
            """
            style: "sql_extractor"
          }

        deepdive.extraction.extractors.cleanup {
          sql: """
          TRUNCATE sentences;
          TRUNCATE has_spouse_candidates;
          TRUNCATE has_spouse;
          TRUNCATE articles;
          TRUNCATE has_spouse_features;
          TRUNCATE people_mentions;
          """
          style: "sql_extractor"
        }

      deepdive.extraction.extractors.ext_has_spouse {
        sql: """ 
        INSERT INTO has_spouse SELECT DISTINCT R0.relation_id, 0 AS id, R0.is_true AS label
          FROM has_spouse_candidates R0
        
          
        """
        style: "sql_extractor"
          dependencies: [ "ext_has_spouse_candidates_by_ext_has_spouse" ]
      }
    

        deepdive.extraction.extractors.ext_people_mentions_by_ext_people {
          input: """ SELECT R0.sentence_id AS "sentences.R0.sentence_id", ARRAY_TO_STRING(R0.words, '~^~') AS column_1, ARRAY_TO_STRING(R0.ner_tags, '~^~') AS column_2
FROM sentences R0
        
          """
          output_relation: "people_mentions"
          udf: ${APP_HOME}"/udf/ext_people.py"
          style: "tsv_extractor" 
          
          input_batch_size: ${INPUT_BATCH_SIZE} 
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.ext_has_spouse_candidates_by_ext_has_spouse {
          input: """ SELECT R0.sentence_id AS "people_mentions.R0.sentence_id", R0.mention_id AS "people_mentions.R0.mention_id", R0.text AS "people_mentions.R0.text", R1.mention_id AS "people_mentions.R1.mention_id", R1.text AS "people_mentions.R1.text"
FROM people_mentions R0, people_mentions R1
        WHERE R1.sentence_id = R0.sentence_id 
          """
          output_relation: "has_spouse_candidates"
          udf: ${APP_HOME}"/udf/ext_has_spouse.py"
          style: "tsv_extractor" 
          dependencies: [ "ext_people_mentions_by_ext_people" ]
          input_batch_size: ${INPUT_BATCH_SIZE} 
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.ext_has_spouse_features_by_ext_has_spouse_features {
          input: """ SELECT ARRAY_TO_STRING(R0.words, '~^~') AS column_0, R1.relation_id AS "has_spouse_candidates.R1.relation_id", R2.start_position AS "people_mentions.R2.start_position", R2.length AS "people_mentions.R2.length", R3.start_position AS "people_mentions.R3.start_position", R3.length AS "people_mentions.R3.length"
FROM sentences R0, has_spouse_candidates R1, people_mentions R2, people_mentions R3
        WHERE R1.sentence_id = R0.sentence_id  AND R2.sentence_id = R0.sentence_id  AND R2.mention_id = R1.person1_id  AND R3.sentence_id = R0.sentence_id  AND R3.mention_id = R1.person2_id 
          """
          output_relation: "has_spouse_features"
          udf: ${APP_HOME}"/udf/ext_has_spouse_features.py"
          style: "tsv_extractor" 
          dependencies: [ "ext_has_spouse_candidates_by_ext_has_spouse" ,  "ext_people_mentions_by_ext_people" ]
          input_batch_size: ${INPUT_BATCH_SIZE} 
          parallelism: ${PARALLELISM}
        }
      

        deepdive.inference.factors.inf_istrue_has_spouse {
          input_query: """
          SELECT R0.id AS "has_spouse.R0.id" , R2.feature AS "dd_weight_column_0" 
          FROM has_spouse R0, has_spouse_candidates R1, has_spouse_features R2
        WHERE R1.relation_id = R0.relation_id  AND R2.relation_id = R0.relation_id """
          function: "Imply(has_spouse.R0.label)"
          weight: "?(dd_weight_column_0)"
        }
      
deepdive.pipeline.run: ${PIPELINE}
deepdive.pipeline.pipelines.initdb: [
  init_sentences
  init_has_spouse_candidates
  init_has_spouse
  init_articles
  init_has_spouse_features
  init_people_mentions
]
deepdive.pipeline.pipelines.extraction: [
  ext_has_spouse
  ext_people_mentions_by_ext_people
  ext_has_spouse_candidates_by_ext_has_spouse
  ext_has_spouse_features_by_ext_has_spouse_features
]
deepdive.pipeline.pipelines.inference: [
  inf_istrue_has_spouse
]
deepdive.pipeline.pipelines.endtoend: [
  ext_has_spouse
  ext_people_mentions_by_ext_people
  ext_has_spouse_candidates_by_ext_has_spouse
  ext_has_spouse_features_by_ext_has_spouse_features
  inf_istrue_has_spouse
]
deepdive.pipeline.pipelines.cleanup: [
  cleanup
]
