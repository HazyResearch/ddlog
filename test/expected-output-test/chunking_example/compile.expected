
  deepdive.db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user: ${PGUSER}
    password: ${PGPASSWORD}
    dbname: ${DBNAME}
    host: ${PGHOST}
    port: ${PGPORT}
    incremental_mode: ORIGINAL
    }
    


      deepdive.schema.variables {
        tag.label: Categorical(13)
      }
    

          deepdive.extraction.extractors.init_words_raw {
            sql: """ DROP TABLE IF EXISTS words_raw CASCADE;
            CREATE TABLE
            words_raw(word_id bigserial,
         word text,
         pos text,
         tag text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_words {
            sql: """ DROP TABLE IF EXISTS words CASCADE;
            CREATE TABLE
            words(sent_id bigint,
     word_id bigint,
     word text,
     pos text,
     true_tag int)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_tag {
            sql: """ DROP TABLE IF EXISTS tag CASCADE;
            CREATE TABLE
            tag(word_id bigint,
   id bigint,
   label int)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_word_features {
            sql: """ DROP TABLE IF EXISTS word_features CASCADE;
            CREATE TABLE
            word_features(word_id bigint,
             feature text)
            """
            style: "sql_extractor"
          }

        deepdive.extraction.extractors.cleanup {
          sql: """
          TRUNCATE words_raw;
          TRUNCATE words;
          TRUNCATE tag;
          TRUNCATE word_features;
          """
          style: "sql_extractor"
        }

      deepdive.extraction.extractors.ext_tag {
        sql: """ 
        INSERT INTO tag SELECT DISTINCT R0.sent_id, 0 AS id, R0.true_tag AS label
          FROM words R0
        
          
        """
        style: "sql_extractor"
          dependencies: [ "ext_words_by_ext_training" ]
      }
    

        deepdive.extraction.extractors.ext_words_by_ext_training {
          input: """ SELECT R0.word_id AS "words_raw.R0.word_id", R0.word AS "words_raw.R0.word", R0.pos AS "words_raw.R0.pos", R0.tag AS "words_raw.R0.tag"
FROM words_raw R0
        
          """
          output_relation: "words"
          udf: ${APP_HOME}"/udf/ext_training.py"
          style: "tsv_extractor" 
         
          input_batch_size: ${INPUT_BATCH_SIZE} 
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.ext_word_features_by_ext_features {
          input: """ SELECT R0.word_id AS "words.R0.word_id", R0.word AS "words.R0.word", R0.pos AS "words.R0.pos", R1.word AS "words.R1.word", R1.pos AS "words.R1.pos"
FROM words R0, words R1
        WHERE R1.sent_id = R0.sent_id 
          """
          output_relation: "word_features"
          udf: ${APP_HOME}"/udf/ext_features.py"
          style: "tsv_extractor" 
          dependencies: [ "ext_words_by_ext_training" ]
          input_batch_size: ${INPUT_BATCH_SIZE} 
          parallelism: ${PARALLELISM}
        }
      

        deepdive.inference.factors.inf_istrue_tag {
          input_query: """
          SELECT R0.id AS "tag.R0.id" , R1.feature AS "dd_weight_column_0" 
          FROM tag R0, word_features R1
        WHERE R1.word_id = R0.word_id """
          function: "Multinomial(tag.R0.label)"
          weight: "?(dd_weight_column_0)"
        }
      
deepdive.pipeline.run: ${PIPELINE}
deepdive.pipeline.pipelines.initdb: [
  init_words_raw
  init_words
  init_tag
  init_word_features
]
deepdive.pipeline.pipelines.extraction: [
  ext_tag
  ext_words_by_ext_training
  ext_word_features_by_ext_features
]
deepdive.pipeline.pipelines.inference: [
  inf_istrue_tag
]
deepdive.pipeline.pipelines.endtoend: [
  ext_tag
  ext_words_by_ext_training
  ext_word_features_by_ext_features
  inf_istrue_tag
]
deepdive.pipeline.pipelines.cleanup: [
  cleanup
]
